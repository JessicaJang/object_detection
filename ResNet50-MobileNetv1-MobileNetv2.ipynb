{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50, MobileNet V1 and MobileNet V2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.engine as KE\n",
    "import keras.models as KM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(KL.BatchNormalization):\n",
    "    \"\"\"\n",
    "    Why we need batch normalization?\n",
    "    Batch normalization is a technique to standardize the inputs\n",
    "    to a neural network, applied to either the activations of a prior layer\n",
    "    or inputs directly\n",
    "    \n",
    "    To prevent internal Covariance shift\n",
    "    distribution can be different\n",
    "    whitening: make input features uncorrelated and set variance as 1'\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    But Batch normalization has a negative effect on training if batches are\n",
    "    small so this layer can be frozen and functions as linear layer\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        return super(self.__class__, self).call(inputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, block, use_bias=True):\n",
    "    \"\"\"\n",
    "    use_bias = True\n",
    "    Weight can decide how fast the activation function will trigger\n",
    "    but bias can delay the trigerring of the activation fucntion\n",
    "    bias can help time-consuming and costly part, i.e. data collection\n",
    "    \n",
    "    If I can set the name, it it easier to retrieve the output to call\n",
    "    Each layer's name\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    x = KL.Conv2D(nb_filter1, (1, 1), use_bias=use_bias)(input_tensor)\n",
    "    x = BatchNorm()(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    x = KL.Conv2D(nb_filter2,(kernel_size, kernel_size), use_bias=use_bias, padding='same')(x)\n",
    "    x = BatchNorm()(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    x = KL.Conv2D(nb_filter3, (1, 1), use_bias=use_bias)(x)\n",
    "    x = BatchNorm()(x)\n",
    "\n",
    "    \n",
    "    x = KL.Add()([x, input_tensor])\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, block, \n",
    "               strides=(2,2), use_bias=True):\n",
    "    \n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    \n",
    "    x = KL.Conv2D(nb_filter1, (1, 1), use_bias=use_bias, \n",
    "                  strides=strides)(input_tensor)\n",
    "    x = BatchNorm()(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    x = KL.Conv2D(nb_filter2,(kernel_size, kernel_size),padding='same', \n",
    "                  use_bias=use_bias)(x)\n",
    "    x = BatchNorm()(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    x = KL.Conv2D(nb_filter3, (1, 1), use_bias=use_bias)(x)\n",
    "    x = BatchNorm()(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    shortcut = KL.Conv2D(nb_filter3, (1, 1), strides=strides, use_bias=use_bias)(input_tensor)\n",
    "    shortcut = BatchNorm()(shortcut)\n",
    "    \n",
    "    x = KL.Add()([x, shortcut])\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def resnet_graph(architecture, input_image=(256,256,3)):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 architecture\n",
    "    CONV2D - Batchnorm - ReLU - MaxPool - CONV - ID*2 - CONV - ID*3 - CONV\n",
    "    - ID*5 - CONV - ID*2 - AVGPOOL-flatten-FC\n",
    "    \"\"\"\n",
    "    \n",
    "    assert architecture in [\"resnet50\", \"resnet101\"]\n",
    "    \n",
    "    X_input = keras.Input(input_image)\n",
    "    # Stage 1\n",
    "    x = KL.ZeroPadding2D((3, 3))(X_input)\n",
    "    x = KL.Conv2D(64, (7, 7), strides=(2, 2), use_bias=True)(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    x = KL.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    \n",
    "    # Stage 2\n",
    "    x = conv_block(x, 3, [64, 64, 256], block='a', strides=(1,1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], block='c')\n",
    "    \n",
    "    # Stage 3\n",
    "    x = conv_block(x, 3, [128, 128, 512], block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], block='d')\n",
    "    \n",
    "    # Stage 4\n",
    "    x = conv_block(x, 3, [256, 256, 1024], block='a')\n",
    "    block_count = {\"resnet50\": 5, \"resnet101\": 22}[architecture]\n",
    "    \n",
    "    for i in range(block_count):\n",
    "        x = identity_block(x, 3, [256, 256, 1024], block=chr(98+i))\n",
    "    \n",
    "    # Stage 5\n",
    "    x = conv_block(x, 3, [512, 512, 2048], block='a', strides=(1,1))\n",
    "    x = identity_block(x, 3, [512, 512, 2048], block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], block='c')\n",
    "    \n",
    "    # AVGPOOL\n",
    "    x = KL.AveragePooling2D()(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    x = KL.Flatten()(x)\n",
    "    x = KL.Dense(4, activation = 'softmax')(x)\n",
    "    \n",
    "\n",
    "    # Create model\n",
    "    model = KM.Model(inputs = X_input, outputs = x, name=architecture)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 model compile and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 262, 262, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 128, 128, 64) 9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 128, 128, 64) 0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_53 (BatchNorm)       (None, 64, 64, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 64, 64, 64)   0           batch_norm_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 64)   36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_54 (BatchNorm)       (None, 64, 64, 64)   256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 64, 64, 64)   0           batch_norm_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 64, 64, 256)  16640       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_55 (BatchNorm)       (None, 64, 64, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 64, 64, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 64, 64, 256)  0           batch_norm_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_56 (BatchNorm)       (None, 64, 64, 256)  1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 64, 64, 256)  0           activation_57[0][0]              \n",
      "                                                                 batch_norm_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 64, 64, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 64, 64, 64)   16448       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_57 (BatchNorm)       (None, 64, 64, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 64, 64, 64)   0           batch_norm_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   36928       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_58 (BatchNorm)       (None, 64, 64, 64)   256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 64, 64, 64)   0           batch_norm_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 256)  16640       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_59 (BatchNorm)       (None, 64, 64, 256)  1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 64, 64, 256)  0           batch_norm_59[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 64, 64, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 64)   16448       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_60 (BatchNorm)       (None, 64, 64, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 64, 64, 64)   0           batch_norm_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 64, 64, 64)   36928       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_61 (BatchNorm)       (None, 64, 64, 64)   256         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 64, 64, 64)   0           batch_norm_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 256)  16640       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_62 (BatchNorm)       (None, 64, 64, 256)  1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 64, 64, 256)  0           batch_norm_62[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 64, 64, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 128)  32896       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_63 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 128)  0           batch_norm_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 128)  147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_64 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 32, 32, 128)  0           batch_norm_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 512)  66048       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_65 (BatchNorm)       (None, 32, 32, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 512)  131584      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 32, 32, 512)  0           batch_norm_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_66 (BatchNorm)       (None, 32, 32, 512)  2048        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 32, 32, 512)  0           activation_67[0][0]              \n",
      "                                                                 batch_norm_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 32, 32, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 128)  65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_67 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 32, 32, 128)  0           batch_norm_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_68 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 32, 32, 128)  0           batch_norm_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 512)  66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_69 (BatchNorm)       (None, 32, 32, 512)  2048        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 32, 32, 512)  0           batch_norm_69[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 32, 32, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 32, 32, 128)  65664       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_70 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 32, 32, 128)  0           batch_norm_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 128)  147584      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_71 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 32, 32, 128)  0           batch_norm_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 512)  66048       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_72 (BatchNorm)       (None, 32, 32, 512)  2048        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 32, 32, 512)  0           batch_norm_72[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 32, 32, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, 32, 128)  65664       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_73 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 32, 32, 128)  0           batch_norm_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 128)  147584      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_74 (BatchNorm)       (None, 32, 32, 128)  512         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 32, 32, 128)  0           batch_norm_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 512)  66048       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_75 (BatchNorm)       (None, 32, 32, 512)  2048        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 32, 32, 512)  0           batch_norm_75[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 32, 32, 512)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 256)  131328      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_76 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 16, 16, 256)  0           batch_norm_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 256)  590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_77 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 256)  0           batch_norm_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 1024) 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_78 (BatchNorm)       (None, 16, 16, 1024) 4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 1024) 525312      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 16, 16, 1024) 0           batch_norm_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_79 (BatchNorm)       (None, 16, 16, 1024) 4096        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 16, 16, 1024) 0           activation_80[0][0]              \n",
      "                                                                 batch_norm_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 16, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 256)  262400      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_80 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 16, 256)  0           batch_norm_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 256)  590080      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_81 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 16, 16, 256)  0           batch_norm_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 1024) 263168      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_82 (BatchNorm)       (None, 16, 16, 1024) 4096        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 16, 16, 1024) 0           batch_norm_82[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 16, 16, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 256)  262400      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_83 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 256)  0           batch_norm_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 256)  590080      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_84 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 256)  0           batch_norm_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 1024) 263168      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_85 (BatchNorm)       (None, 16, 16, 1024) 4096        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 16, 16, 1024) 0           batch_norm_85[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 256)  262400      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_86 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 256)  0           batch_norm_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 256)  590080      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_87 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 256)  0           batch_norm_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 1024) 263168      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_88 (BatchNorm)       (None, 16, 16, 1024) 4096        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 16, 16, 1024) 0           batch_norm_88[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 16, 16, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 256)  262400      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_89 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 16, 16, 256)  0           batch_norm_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 256)  590080      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_90 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 16, 16, 256)  0           batch_norm_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 16, 16, 1024) 263168      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_91 (BatchNorm)       (None, 16, 16, 1024) 4096        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 16, 16, 1024) 0           batch_norm_91[0][0]              \n",
      "                                                                 activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 16, 16, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 16, 16, 256)  262400      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_92 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 16, 16, 256)  0           batch_norm_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 16, 16, 256)  590080      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_93 (BatchNorm)       (None, 16, 16, 256)  1024        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 16, 16, 256)  0           batch_norm_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 16, 16, 1024) 263168      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_94 (BatchNorm)       (None, 16, 16, 1024) 4096        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 16, 16, 1024) 0           batch_norm_94[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 16, 16, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 512)  524800      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_95 (BatchNorm)       (None, 16, 16, 512)  2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 16, 16, 512)  0           batch_norm_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 512)  2359808     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_96 (BatchNorm)       (None, 16, 16, 512)  2048        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 16, 16, 512)  0           batch_norm_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 2048) 1050624     activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_97 (BatchNorm)       (None, 16, 16, 2048) 8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 2048) 2099200     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 2048) 0           batch_norm_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_98 (BatchNorm)       (None, 16, 16, 2048) 8192        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 16, 16, 2048) 0           activation_99[0][0]              \n",
      "                                                                 batch_norm_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 2048) 0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 512)  1049088     activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_99 (BatchNorm)       (None, 16, 16, 512)  2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 512)  0           batch_norm_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 512)  2359808     activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_100 (BatchNorm)      (None, 16, 16, 512)  2048        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 512)  0           batch_norm_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 2048) 1050624     activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_101 (BatchNorm)      (None, 16, 16, 2048) 8192        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 2048) 0           batch_norm_101[0][0]             \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 2048) 0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 512)  1049088     activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_102 (BatchNorm)      (None, 16, 16, 512)  2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 512)  0           batch_norm_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 512)  2359808     activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_103 (BatchNorm)      (None, 16, 16, 512)  2048        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 512)  0           batch_norm_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 2048) 1050624     activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_104 (BatchNorm)      (None, 16, 16, 2048) 8192        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 2048) 0           batch_norm_104[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 2048) 0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 2048)   0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 131072)       0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            524292      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,111,748\n",
      "Trainable params: 24,058,756\n",
      "Non-trainable params: 52,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnetModel = resnet_graph(\"resnet50\")\n",
    "sgd = keras.optimizers.SGD(lr=1e-6)\n",
    "resnetModel.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "resnetModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet V1 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MobileNet v1 models for Keras.\n",
    "# Reference\n",
    "- [MobineNets: Efficient Convolutional Neural Networks for Mobile Vision Applications]\n",
    "   (https://arxiv.org/abs/1704.04861)\n",
    "# Code modified from: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/mobilenet.py\n",
    "\"\"\"\n",
    "\n",
    "def _conv_block(input_tensor, filters, alpha, kernel_size=3, strides=(1, 1), block_id=1, use_bias=True):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    \n",
    "    alpha: controls the width of the network. - If `alpha` < 1.0,\n",
    "      proportionally decreases the number of filters in each layer. - If\n",
    "      `alpha` > 1.0, proportionally increases the number of filters in each\n",
    "      layer. - If `alpha` = 1, default number of filters from the paper are\n",
    "      used at each layer.\n",
    "      \n",
    "    4D tensor with shape: `(samples, channels, rows, cols)` if\n",
    "      data_format='channels_first'\n",
    "    or 4D tensor with shape: `(samples, rows, cols, channels)` if\n",
    "      data_format='channels_last'. # Output shape\n",
    "    \n",
    "    \"\"\"\n",
    "    print(input_tensor.shape)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    \n",
    "    filters = int(filters * alpha)\n",
    "    x = KL.Conv2D(filters, (kernel_size, kernel_size), \n",
    "                  padding='same',\n",
    "                  use_bias=False, \n",
    "                  strides=strides,\n",
    "                  name='conv{}'.format(block_id))(input_tensor)\n",
    "    x = BatchNorm(axis=channel_axis, name='conv{}_bn'.format(block_id))(x)\n",
    "    x = KL.Activation('relu', name='conv{}_relu'.format(block_id))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _depth_conv_block(input_tensor, pointwise_conv_filters, alpha, depth_multiplier=1, strides=(1,1), block_id=1):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    pointwise_conv_filters: Integer, the dimensionality o the output space\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "    \n",
    "    # Depthwise\n",
    "    x = KL.DepthwiseConv2D((3, 3),\n",
    "                           padding='same',\n",
    "                           depth_multiplier=depth_multiplier,\n",
    "                           strides=strides,\n",
    "                           use_bias=False,\n",
    "                           name='conv_depth{}'.format(block_id))(input_tensor)\n",
    "    x = BatchNorm(axis=channel_axis, name='conv_depth{}_bn'.format(block_id))(x)\n",
    "    x = KL.Activation('relu', name='conv_depth{}_relu'.format(block_id))(x)\n",
    "    \n",
    "    # Pointwise\n",
    "    x = KL.Conv2D(pointwise_conv_filters, (1,1), padding='same',\n",
    "                  use_bias=False,\n",
    "                  strides=(1,1),\n",
    "                  name='conv_point{}'.format(block_id))(x)\n",
    "    x = BatchNorm(axis=channel_axis, name='conv_point{}_bn'.format(block_id))(x)\n",
    "    x = KL.Activation('relu', name='conv_point{}_relu'.format(block_id))(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv1_graph(architecture, input_image=(512,512,3), alpha=1.0, depth_multiplier=1):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "    input_shape: Optional shape tuple, only to be specified if `include_top`\n",
    "      is False (otherwise the input shape has to be `(224, 224, 3)` (with\n",
    "      `channels_last` data format) or (3, 224, 224) (with `channels_first`\n",
    "      data format). It should have exactly 3 inputs channels, and width and\n",
    "      height should be no smaller than 32. E.g. `(200, 200, 3)` would be one\n",
    "      valid value. Default to `None`.\n",
    "      `input_shape` will be ignored if the `input_tensor` is provided.\n",
    "    alpha: Controls the width of the network. This is known as the width\n",
    "      multiplier in the MobileNet paper. - If `alpha` < 1.0, proportionally\n",
    "      decreases the number of filters in each layer. - If `alpha` > 1.0,\n",
    "      proportionally increases the number of filters in each layer. - If\n",
    "      `alpha` = 1, default number of filters from the paper are used at each\n",
    "      layer. Default to 1.0.\n",
    "    depth_multiplier: Depth multiplier for depthwise convolution. This is\n",
    "      called the resolution multiplier in the MobileNet paper. Default to 1.0.\n",
    "    dropout: Dropout rate. Default to 0.001.\n",
    "    include_top: Boolean, whether to include the fully-connected layer at the\n",
    "      top of the network. Default to `True`.\n",
    "    weights: One of `None` (random initialization), 'imagenet' (pre-training\n",
    "      on ImageNet), or the path to the weights file to be loaded. Default to\n",
    "      `imagenet`.\n",
    "    input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`) to\n",
    "      use as image input for the model. `input_tensor` is useful for sharing\n",
    "      inputs between multiple different networks. Default to None.\n",
    "    pooling: Optional pooling mode for feature extraction when `include_top`\n",
    "      is `False`.\n",
    "      - `None` (default) means that the output of the model will be\n",
    "          the 4D tensor output of the last convolutional block.\n",
    "      - `avg` means that global average pooling\n",
    "          will be applied to the output of the\n",
    "          last convolutional block, and thus\n",
    "          the output of the model will be a 2D tensor.\n",
    "      - `max` means that global max pooling will be applied.\n",
    "    classes: Optional number of classes to classify images into, only to be\n",
    "      specified if `include_top` is True, and if no `weights` argument is\n",
    "      specified. Defaults to 1000.\n",
    "    classifier_activation: A `str` or callable. The activation function to use\n",
    "      on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
    "      `classifier_activation=None` to return the logits of the \"top\" layer.\n",
    "    **kwargs: For backwards compatibility only.\n",
    "  Returns:\n",
    "    A `keras.Model` instance.\n",
    "  Raises:\n",
    "    ValueError: in case of invalid argument for `weights`,\n",
    "      or invalid input shape.\n",
    "    ValueError: if `classifier_activation` is not `softmax` or `None` when\n",
    "      using a pretrained top layer.\n",
    "  \"\"\"\n",
    "    assert architecture in [\"mobilenetv1\"]\n",
    "    X_input = keras.Input(input_image)\n",
    "    x = _conv_block(X_input, 32, alpha, strides=(2,2), block_id=0)\n",
    "    x = _depth_conv_block(x, 64, alpha, strides=(1,1), block_id=1)\n",
    "    \n",
    "    x = _depth_conv_block(x, 128, alpha, depth_multiplier, strides=(2,2), block_id=2)\n",
    "    x = _depth_conv_block(x, 128, alpha, depth_multiplier, strides=(1,1), block_id=3)\n",
    "    \n",
    "    x = _depth_conv_block(x, 256, alpha, depth_multiplier, strides=(2,2), block_id=4)\n",
    "    x = _depth_conv_block(x, 256, alpha, depth_multiplier, strides=(1,1), block_id=5)\n",
    "    \n",
    "    x = _depth_conv_block(x, 512, alpha, depth_multiplier, strides=(2,2), block_id=6)\n",
    "    x = _depth_conv_block(x, 512, alpha, depth_multiplier, strides=(1,1), block_id=7)\n",
    "    x = _depth_conv_block(x, 512, alpha, depth_multiplier, strides=(1,1), block_id=8)\n",
    "    x = _depth_conv_block(x, 512, alpha, depth_multiplier, strides=(1,1), block_id=9)\n",
    "    x = _depth_conv_block(x, 512, alpha, depth_multiplier, strides=(1,1), block_id=10)\n",
    "    x = _depth_conv_block(x, 512, alpha, depth_multiplier, strides=(1,1), block_id=11)\n",
    "    \n",
    "    x = _depth_conv_block(x, 1024, alpha, depth_multiplier, strides=(2,2), block_id=12)\n",
    "    x = _depth_conv_block(x, 1024, alpha, depth_multiplier, strides=(1,1), block_id=13)\n",
    "    \n",
    "    shape = (int(1024*alpha), 1, 1) if K.image_data_format() == 'channel_first' else (1,1,int(1024*alpha))\n",
    "    # pooling and FC and activation function, After extracting features\n",
    "    # Output Layer\n",
    "    x = KL.GlobalAveragePooling2D()(x)\n",
    "    x = KL.Reshape(shape, name='reshape_1')(x)\n",
    "    x = KL.Dropout(1e-6, name='dropout')(x)\n",
    "    x = KL.Conv2D(4, (1,1), padding='same', name='conv_preds')(x)\n",
    "    x = KL.Reshape((4,), name='reshape_2')(x)\n",
    "    x = KL.Activation('softmax', name='predictions')(x)\n",
    "    \n",
    "    model = KM.Model(inputs = X_input, outputs = x, name=architecture)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 512, 512, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 256, 256, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv0_bn (BatchNorm)         (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv0_relu (Activation)      (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_depth1 (DepthwiseConv2D (None, 256, 256, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_depth1_bn (BatchNorm)   (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_depth1_relu (Activation (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_point1 (Conv2D)         (None, 256, 256, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_point1_bn (BatchNorm)   (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_point1_relu (Activation (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_depth2 (DepthwiseConv2D (None, 128, 128, 64)      576       \n",
      "_________________________________________________________________\n",
      "conv_depth2_bn (BatchNorm)   (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_depth2_relu (Activation (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_point2 (Conv2D)         (None, 128, 128, 128)     8192      \n",
      "_________________________________________________________________\n",
      "conv_point2_bn (BatchNorm)   (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv_point2_relu (Activation (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_depth3 (DepthwiseConv2D (None, 128, 128, 128)     1152      \n",
      "_________________________________________________________________\n",
      "conv_depth3_bn (BatchNorm)   (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv_depth3_relu (Activation (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_point3 (Conv2D)         (None, 128, 128, 128)     16384     \n",
      "_________________________________________________________________\n",
      "conv_point3_bn (BatchNorm)   (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv_point3_relu (Activation (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_depth4 (DepthwiseConv2D (None, 64, 64, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_depth4_bn (BatchNorm)   (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_depth4_relu (Activation (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_point4 (Conv2D)         (None, 64, 64, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_point4_bn (BatchNorm)   (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_point4_relu (Activation (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth5 (DepthwiseConv2D (None, 64, 64, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_depth5_bn (BatchNorm)   (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_depth5_relu (Activation (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_point5 (Conv2D)         (None, 64, 64, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_point5_bn (BatchNorm)   (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_point5_relu (Activation (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth6 (DepthwiseConv2D (None, 32, 32, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_depth6_bn (BatchNorm)   (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_depth6_relu (Activation (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_point6 (Conv2D)         (None, 32, 32, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_point6_bn (BatchNorm)   (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_point6_relu (Activation (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth7 (DepthwiseConv2D (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_depth7_bn (BatchNorm)   (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_depth7_relu (Activation (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_point7 (Conv2D)         (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_point7_bn (BatchNorm)   (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_point7_relu (Activation (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth8 (DepthwiseConv2D (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_depth8_bn (BatchNorm)   (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_depth8_relu (Activation (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_point8 (Conv2D)         (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_point8_bn (BatchNorm)   (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_point8_relu (Activation (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth9 (DepthwiseConv2D (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_depth9_bn (BatchNorm)   (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_depth9_relu (Activation (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_point9 (Conv2D)         (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_point9_bn (BatchNorm)   (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_point9_relu (Activation (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth10 (DepthwiseConv2 (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_depth10_bn (BatchNorm)  (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_depth10_relu (Activatio (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_point10 (Conv2D)        (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_point10_bn (BatchNorm)  (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_point10_relu (Activatio (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth11 (DepthwiseConv2 (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_depth11_bn (BatchNorm)  (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_depth11_relu (Activatio (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_point11 (Conv2D)        (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_point11_bn (BatchNorm)  (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_point11_relu (Activatio (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_depth12 (DepthwiseConv2 (None, 16, 16, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_depth12_bn (BatchNorm)  (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_depth12_relu (Activatio (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_point12 (Conv2D)        (None, 16, 16, 1024)      524288    \n",
      "_________________________________________________________________\n",
      "conv_point12_bn (BatchNorm)  (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv_point12_relu (Activatio (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv_depth13 (DepthwiseConv2 (None, 16, 16, 1024)      9216      \n",
      "_________________________________________________________________\n",
      "conv_depth13_bn (BatchNorm)  (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv_depth13_relu (Activatio (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv_point13 (Conv2D)        (None, 16, 16, 1024)      1048576   \n",
      "_________________________________________________________________\n",
      "conv_point13_bn (BatchNorm)  (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv_point13_relu (Activatio (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 4)           4100      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 3,211,076\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenetv1Model = mobilenetv1_graph(\"mobilenetv1\")\n",
    "sgd = keras.optimizers.SGD(lr=1e-6)\n",
    "mobilenetv1Model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "mobilenetv1Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet V2 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MobileNet v2 models for Keras.\n",
    "# Reference\n",
    "- [MobileNetV2: Inverted Residuals and Linear Bottlenecks]\n",
    "   (https://arxiv.org/abs/1801.04381)\n",
    "# Code modified from: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/mobilenet.py\n",
    "\"\"\"\n",
    "def _inverted_res_block(inputs, filters, kernel, stride, expansion, block_id, alpha=1.0):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channel_first' else -1\n",
    "    \n",
    "    in_channel = K.int_shape(inputs)[channel_axis]\n",
    "    pointwise_conv_filters = int(filters * alpha)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "    \n",
    "    x = inputs\n",
    "    x = _conv_block(inputs, expansion * in_channel, alpha, 1, (1, 1), block_id=block_id)\n",
    "\n",
    "    x = KL.DepthwiseConv2D(kernel, strides=stride, depth_multiplier=1, padding='same', name='conv_dw_{}'.format(block_id))(x)\n",
    "    x = BatchNorm(axis=channel_axis, name='conv_dw_{}_bn'.format(block_id))(x)\n",
    "    x = KL.Activation('relu', name='conv_dw{}_relu'.format(block_id))(x)\n",
    "    \n",
    "    x = KL.Conv2D(pointwise_filters, (1, 1), strides=(1, 1), padding='same', name='conv_pw_{}'.format(block_id))(x)\n",
    "    x = BatchNorm(axis=channel_axis, name='conv_pw_{}_bn'.format(block_id))(x)\n",
    "    \n",
    "    if stride == (1,1) and pointwise_filters==filters and x.shape[-1] == inputs.shape[-1]: \n",
    "        x = KL.add([x, inputs], name='res{}'.format(block_id))\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None: min_value = divisor\n",
    "    new_v = max(min_value, int(v+divisor/2) // divisor*divisor)\n",
    "    \n",
    "    if new_v < 0.9 * v: new_v += divisor\n",
    "    \n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv2_graph(architecture, inputs=(224,224,3), alpha=1.0):\n",
    "    assert architecture in [\"mobilenetv2\"]\n",
    "    X_input = keras.Input(inputs)\n",
    "    \n",
    "    x = _conv_block(X_input, 32, alpha, strides=(2,2), block_id=0)\n",
    "    \n",
    "    x = _inverted_res_block(x, 16, 3, (1,1), 1, block_id=1)\n",
    "    \n",
    "    x = _inverted_res_block(x, 24, 3, (2,2), 6, block_id=2)\n",
    "    x = _inverted_res_block(x, 24, 3, (1,1), 6, block_id=3)\n",
    "    \n",
    "    x = _inverted_res_block(x, 32, 3, (2,2), 6, block_id=4)\n",
    "    x = _inverted_res_block(x, 32, 3, (1,1), 6, block_id=5)\n",
    "    x = _inverted_res_block(x, 32, 3, (1,1), 6, block_id=6)\n",
    "    \n",
    "    x = _inverted_res_block(x, 64, 3, (2,2), 6, block_id=7)\n",
    "    x = _inverted_res_block(x, 64, 3, (1,1), 6, block_id=8)\n",
    "    x = _inverted_res_block(x, 64, 3, (1,1), 6, block_id=9)\n",
    "    x = _inverted_res_block(x, 64, 3, (1,1), 6, block_id=10)\n",
    "    \n",
    "    x = _inverted_res_block(x, 96, 3, (1,1), 6, block_id=11)\n",
    "    x = _inverted_res_block(x, 96, 3, (1,1), 6, block_id=12)\n",
    "    x = _inverted_res_block(x, 96, 3, (1,1), 6, block_id=13)\n",
    "    \n",
    "    x = _inverted_res_block(x, 160, 3, (2,2), 6, block_id=14)\n",
    "    x = _inverted_res_block(x, 160, 3, (1,1), 6, block_id=15)\n",
    "    x = _inverted_res_block(x, 160, 3, (1,1), 6, block_id=16)\n",
    "    \n",
    "    x = _inverted_res_block(x, 320, 3, (1,1), 6, block_id=17)\n",
    "    \n",
    "    last_block_filters = 1280\n",
    "    x = KL.Conv2D(last_block_filters, 1, use_bias=False, name='last_conv_1')(x)\n",
    "    x = BatchNorm(axis=-1, name='last_bn_1')(x)\n",
    "    x = KL.Activation('relu', name='last_relu')(x)\n",
    "    x = KL.GlobalAveragePooling2D()(x)\n",
    "    x = KL.Dense(4, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = KM.Model(inputs=X_input, output=x, name=architecture)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 112, 112, 32) 864         input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv0_bn (BatchNorm)            (None, 112, 112, 32) 128         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv0_relu (Activation)         (None, 112, 112, 32) 0           conv0_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 32) 1024        conv0_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNorm)            (None, 112, 112, 32) 128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 32) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)     (None, 112, 112, 32) 320         conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_1_bn (BatchNorm)        (None, 112, 112, 32) 128         conv_dw_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw1_relu (Activation)      (None, 112, 112, 32) 0           conv_dw_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_1 (Conv2D)              (None, 112, 112, 16) 528         conv_dw1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_1_bn (BatchNorm)        (None, 112, 112, 16) 64          conv_pw_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 112, 112, 96) 1536        conv_pw_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_bn (BatchNorm)            (None, 112, 112, 96) 384         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_relu (Activation)         (None, 112, 112, 96) 0           conv2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)     (None, 56, 56, 96)   960         conv2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2_bn (BatchNorm)        (None, 56, 56, 96)   384         conv_dw_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw2_relu (Activation)      (None, 56, 56, 96)   0           conv_dw_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2 (Conv2D)              (None, 56, 56, 24)   2328        conv_dw2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2_bn (BatchNorm)        (None, 56, 56, 24)   96          conv_pw_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 56, 56, 144)  3456        conv_pw_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_bn (BatchNorm)            (None, 56, 56, 144)  576         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_relu (Activation)         (None, 56, 56, 144)  0           conv3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)     (None, 56, 56, 144)  1440        conv3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3_bn (BatchNorm)        (None, 56, 56, 144)  576         conv_dw_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw3_relu (Activation)      (None, 56, 56, 144)  0           conv_dw_3_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3 (Conv2D)              (None, 56, 56, 24)   3480        conv_dw3_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3_bn (BatchNorm)        (None, 56, 56, 24)   96          conv_pw_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3 (Add)                      (None, 56, 56, 24)   0           conv_pw_3_bn[0][0]               \n",
      "                                                                 conv_pw_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 56, 56, 144)  3456        res3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_bn (BatchNorm)            (None, 56, 56, 144)  576         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_relu (Activation)         (None, 56, 56, 144)  0           conv4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)     (None, 28, 28, 144)  1440        conv4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_bn (BatchNorm)        (None, 28, 28, 144)  576         conv_dw_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw4_relu (Activation)      (None, 28, 28, 144)  0           conv_dw_4_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4 (Conv2D)              (None, 28, 28, 32)   4640        conv_dw4_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_bn (BatchNorm)        (None, 28, 28, 32)   128         conv_pw_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 28, 28, 192)  6144        conv_pw_4_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_bn (BatchNorm)            (None, 28, 28, 192)  768         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_relu (Activation)         (None, 28, 28, 192)  0           conv5_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)     (None, 28, 28, 192)  1920        conv5_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_bn (BatchNorm)        (None, 28, 28, 192)  768         conv_dw_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw5_relu (Activation)      (None, 28, 28, 192)  0           conv_dw_5_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5 (Conv2D)              (None, 28, 28, 32)   6176        conv_dw5_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_bn (BatchNorm)        (None, 28, 28, 32)   128         conv_pw_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res5 (Add)                      (None, 28, 28, 32)   0           conv_pw_5_bn[0][0]               \n",
      "                                                                 conv_pw_4_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 28, 28, 192)  6144        res5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv6_bn (BatchNorm)            (None, 28, 28, 192)  768         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6_relu (Activation)         (None, 28, 28, 192)  0           conv6_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)     (None, 28, 28, 192)  1920        conv6_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6_bn (BatchNorm)        (None, 28, 28, 192)  768         conv_dw_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw6_relu (Activation)      (None, 28, 28, 192)  0           conv_dw_6_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6 (Conv2D)              (None, 28, 28, 32)   6176        conv_dw6_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6_bn (BatchNorm)        (None, 28, 28, 32)   128         conv_pw_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res6 (Add)                      (None, 28, 28, 32)   0           conv_pw_6_bn[0][0]               \n",
      "                                                                 res5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 28, 28, 192)  6144        res6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv7_bn (BatchNorm)            (None, 28, 28, 192)  768         conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv7_relu (Activation)         (None, 28, 28, 192)  0           conv7_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)     (None, 14, 14, 192)  1920        conv7_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7_bn (BatchNorm)        (None, 14, 14, 192)  768         conv_dw_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw7_relu (Activation)      (None, 14, 14, 192)  0           conv_dw_7_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7 (Conv2D)              (None, 14, 14, 64)   12352       conv_dw7_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7_bn (BatchNorm)        (None, 14, 14, 64)   256         conv_pw_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv8 (Conv2D)                  (None, 14, 14, 384)  24576       conv_pw_7_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv8_bn (BatchNorm)            (None, 14, 14, 384)  1536        conv8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv8_relu (Activation)         (None, 14, 14, 384)  0           conv8_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)     (None, 14, 14, 384)  3840        conv8_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_bn (BatchNorm)        (None, 14, 14, 384)  1536        conv_dw_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw8_relu (Activation)      (None, 14, 14, 384)  0           conv_dw_8_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8 (Conv2D)              (None, 14, 14, 64)   24640       conv_dw8_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_bn (BatchNorm)        (None, 14, 14, 64)   256         conv_pw_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res8 (Add)                      (None, 14, 14, 64)   0           conv_pw_8_bn[0][0]               \n",
      "                                                                 conv_pw_7_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9 (Conv2D)                  (None, 14, 14, 384)  24576       res8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv9_bn (BatchNorm)            (None, 14, 14, 384)  1536        conv9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv9_relu (Activation)         (None, 14, 14, 384)  0           conv9_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)     (None, 14, 14, 384)  3840        conv9_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_bn (BatchNorm)        (None, 14, 14, 384)  1536        conv_dw_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw9_relu (Activation)      (None, 14, 14, 384)  0           conv_dw_9_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9 (Conv2D)              (None, 14, 14, 64)   24640       conv_dw9_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_bn (BatchNorm)        (None, 14, 14, 64)   256         conv_pw_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res9 (Add)                      (None, 14, 14, 64)   0           conv_pw_9_bn[0][0]               \n",
      "                                                                 res8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 14, 14, 384)  24576       res9[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv10_bn (BatchNorm)           (None, 14, 14, 384)  1536        conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv10_relu (Activation)        (None, 14, 14, 384)  0           conv10_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D)    (None, 14, 14, 384)  3840        conv10_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_bn (BatchNorm)       (None, 14, 14, 384)  1536        conv_dw_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw10_relu (Activation)     (None, 14, 14, 384)  0           conv_dw_10_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10 (Conv2D)             (None, 14, 14, 64)   24640       conv_dw10_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_bn (BatchNorm)       (None, 14, 14, 64)   256         conv_pw_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res10 (Add)                     (None, 14, 14, 64)   0           conv_pw_10_bn[0][0]              \n",
      "                                                                 res9[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv11 (Conv2D)                 (None, 14, 14, 384)  24576       res10[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv11_bn (BatchNorm)           (None, 14, 14, 384)  1536        conv11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv11_relu (Activation)        (None, 14, 14, 384)  0           conv11_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D)    (None, 14, 14, 384)  3840        conv11_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_bn (BatchNorm)       (None, 14, 14, 384)  1536        conv_dw_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw11_relu (Activation)     (None, 14, 14, 384)  0           conv_dw_11_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11 (Conv2D)             (None, 14, 14, 96)   36960       conv_dw11_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_bn (BatchNorm)       (None, 14, 14, 96)   384         conv_pw_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv12 (Conv2D)                 (None, 14, 14, 576)  55296       conv_pw_11_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv12_bn (BatchNorm)           (None, 14, 14, 576)  2304        conv12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv12_relu (Activation)        (None, 14, 14, 576)  0           conv12_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D)    (None, 14, 14, 576)  5760        conv12_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_bn (BatchNorm)       (None, 14, 14, 576)  2304        conv_dw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw12_relu (Activation)     (None, 14, 14, 576)  0           conv_dw_12_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12 (Conv2D)             (None, 14, 14, 96)   55392       conv_dw12_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_bn (BatchNorm)       (None, 14, 14, 96)   384         conv_pw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res12 (Add)                     (None, 14, 14, 96)   0           conv_pw_12_bn[0][0]              \n",
      "                                                                 conv_pw_11_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv13 (Conv2D)                 (None, 14, 14, 576)  55296       res12[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv13_bn (BatchNorm)           (None, 14, 14, 576)  2304        conv13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv13_relu (Activation)        (None, 14, 14, 576)  0           conv13_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D)    (None, 14, 14, 576)  5760        conv13_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_bn (BatchNorm)       (None, 14, 14, 576)  2304        conv_dw_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw13_relu (Activation)     (None, 14, 14, 576)  0           conv_dw_13_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13 (Conv2D)             (None, 14, 14, 96)   55392       conv_dw13_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_bn (BatchNorm)       (None, 14, 14, 96)   384         conv_pw_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res13 (Add)                     (None, 14, 14, 96)   0           conv_pw_13_bn[0][0]              \n",
      "                                                                 res12[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv14 (Conv2D)                 (None, 14, 14, 576)  55296       res13[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv14_bn (BatchNorm)           (None, 14, 14, 576)  2304        conv14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv14_relu (Activation)        (None, 14, 14, 576)  0           conv14_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14 (DepthwiseConv2D)    (None, 7, 7, 576)    5760        conv14_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_bn (BatchNorm)       (None, 7, 7, 576)    2304        conv_dw_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw14_relu (Activation)     (None, 7, 7, 576)    0           conv_dw_14_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14 (Conv2D)             (None, 7, 7, 160)    92320       conv_dw14_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14_bn (BatchNorm)       (None, 7, 7, 160)    640         conv_pw_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv15 (Conv2D)                 (None, 7, 7, 960)    153600      conv_pw_14_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv15_bn (BatchNorm)           (None, 7, 7, 960)    3840        conv15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv15_relu (Activation)        (None, 7, 7, 960)    0           conv15_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15 (DepthwiseConv2D)    (None, 7, 7, 960)    9600        conv15_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_bn (BatchNorm)       (None, 7, 7, 960)    3840        conv_dw_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw15_relu (Activation)     (None, 7, 7, 960)    0           conv_dw_15_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15 (Conv2D)             (None, 7, 7, 160)    153760      conv_dw15_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15_bn (BatchNorm)       (None, 7, 7, 160)    640         conv_pw_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res15 (Add)                     (None, 7, 7, 160)    0           conv_pw_15_bn[0][0]              \n",
      "                                                                 conv_pw_14_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv16 (Conv2D)                 (None, 7, 7, 960)    153600      res15[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv16_bn (BatchNorm)           (None, 7, 7, 960)    3840        conv16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv16_relu (Activation)        (None, 7, 7, 960)    0           conv16_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_16 (DepthwiseConv2D)    (None, 7, 7, 960)    9600        conv16_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_16_bn (BatchNorm)       (None, 7, 7, 960)    3840        conv_dw_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw16_relu (Activation)     (None, 7, 7, 960)    0           conv_dw_16_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_16 (Conv2D)             (None, 7, 7, 160)    153760      conv_dw16_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_16_bn (BatchNorm)       (None, 7, 7, 160)    640         conv_pw_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res16 (Add)                     (None, 7, 7, 160)    0           conv_pw_16_bn[0][0]              \n",
      "                                                                 res15[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv17 (Conv2D)                 (None, 7, 7, 960)    153600      res16[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv17_bn (BatchNorm)           (None, 7, 7, 960)    3840        conv17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv17_relu (Activation)        (None, 7, 7, 960)    0           conv17_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_17 (DepthwiseConv2D)    (None, 7, 7, 960)    9600        conv17_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_17_bn (BatchNorm)       (None, 7, 7, 960)    3840        conv_dw_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw17_relu (Activation)     (None, 7, 7, 960)    0           conv_dw_17_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_17 (Conv2D)             (None, 7, 7, 320)    307520      conv_dw17_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_17_bn (BatchNorm)       (None, 7, 7, 320)    1280        conv_pw_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "last_conv_1 (Conv2D)            (None, 7, 7, 1280)   409600      conv_pw_17_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "last_bn_1 (BatchNorm)           (None, 7, 7, 1280)   5120        last_conv_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "last_relu (Activation)          (None, 7, 7, 1280)   0           last_bn_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 1280)         0           last_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 4)            5124        global_average_pooling2d_13[0][0]\n",
      "==================================================================================================\n",
      "Total params: 2,272,900\n",
      "Trainable params: 2,238,724\n",
      "Non-trainable params: 34,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwon\\anaconda3\\envs\\GPUtest2\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., name=\"mobilenetv2\", outputs=Tensor(\"pr...)`\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2Model = mobilenetv2_graph(\"mobilenetv2\")\n",
    "sgd = keras.optimizers.SGD(lr=1e-6)\n",
    "mobilenetv2Model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "mobilenetv2Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
